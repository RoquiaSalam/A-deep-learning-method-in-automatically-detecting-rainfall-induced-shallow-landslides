{"cells":[{"cell_type":"markdown","metadata":{"id":"hK7GV0CN8lYP"},"source":["## Application of deep learning method in automatically detecting rainfall-induced shallow landslides in a data-sparse context\n","Roquia Salam, Filiberto Pla Bañón, Bayes Ahmed, Marco Painho\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Mount Google Drive and install necessary libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24959,"status":"ok","timestamp":1711707854137,"user":{"displayName":"Esha Bru","userId":"05925107127092817314"},"user_tz":0},"id":"qyXHj9VUWvuz","outputId":"b1a607ee-3252-4f4e-c44e-206cdaf42dcc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9AKMwtxNWfw2"},"outputs":[],"source":["!pip install segmentation_models rasterio geopandas contextily # This line will install the packages/libraries which are not present in Google Colab."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KBuf0QykfEph"},"outputs":[],"source":["!pip install -U -q segmentation-models  # you may need to adjust according to your device configuration\n","!pip install -q tensorflow==2.2.1\n","!pip install -q keras==2.5\n","import os\n","os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n","\n","from tensorflow import keras\n","import segmentation_models as sm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":902,"status":"ok","timestamp":1711707927647,"user":{"displayName":"Esha Bru","userId":"05925107127092817314"},"user_tz":0},"id":"K-y14rFpVRLS","outputId":"d407505d-2320-4c8b-aea9-adcbc16729c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Default GPU Device:/device:GPU:0\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import layers\n","from tensorflow import keras\n","import pandas as pd\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","\n","import sys\n","sys.path.append('/content/drive/MyDrive/Data for the experiment/Fold 4') # mention your folder in the google drive where your data is stored\n","\n","\n","physical_devices = tf.config.experimental.list_physical_devices('GPU')\n","\n","for device in physical_devices:\n","    tf.config.experimental.set_memory_growth(device, True)\n","\n","if tf.test.gpu_device_name():\n","\n","    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n","else:\n","   print(\"Please install GPU version of TF\")"]},{"cell_type":"markdown","metadata":{"id":"vN_fdjiA9N10"},"source":["## Load the NumPy arrays which contains the training, validation, and testing data\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5669,"status":"ok","timestamp":1711707965830,"user":{"displayName":"Esha Bru","userId":"05925107127092817314"},"user_tz":0},"id":"_lR2TSa0Wm6e","outputId":"8df4491d-dada-4159-aa65-34104f11c907"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of the training dataset (satellite image):  (1000, 64, 64, 4)\n","Shape of the training dataset (label image):  (1000, 64, 64, 1)\n","Shape of the validation dataset (satellite image):  (500, 64, 64, 4)\n","Shape of the validation dataset (label image):  (500, 64, 64, 1)\n","Shape of the testing dataset (satellite image):  (500, 64, 64, 4)\n","Shape of the testing dataset (label image):  (500, 64, 64, 1)\n"]}],"source":["X_train = np.load(f'/content/drive/MyDrive/Data for the experiment/Fold 4/Xtrain.npy')  #mention the path of the data\n","Y_train = np.load(f'/content/drive/MyDrive/Data for the experiment/Fold 4/Ytrain.npy')\n","X_val = np.load(f'/content/drive/MyDrive/Data for the experiment/Fold 4/Xval.npy')\n","Y_val = np.load(f'/content/drive/MyDrive/Data for the experiment/Fold 4/Yval.npy')\n","X_test = np.load(f'/content/drive/MyDrive/Data for the experiment/Fold 4/Xtest.npy')\n","Y_test = np.load(f'/content/drive/MyDrive/Data for the experiment/Fold 4/Ytest.npy')\n","\n","\n","print(\"Shape of the training dataset (satellite image): \", X_train.shape)\n","print(\"Shape of the training dataset (label image): \",Y_train.shape)\n","print(\"Shape of the validation dataset (satellite image): \",X_val.shape)\n","print(\"Shape of the validation dataset (label image): \",Y_val.shape)\n","print(\"Shape of the testing dataset (satellite image): \",X_test.shape)\n","print(\"Shape of the testing dataset (label image): \",Y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42spYJQZWt43"},"outputs":[],"source":["# Visualise some data\n","for i in range(5):\n","    f, axarr = plt.subplots(1,2,figsize=(8,8))\n","    axarr[0].imshow(X_train[i][:,:,:3])\n","    axarr[0].set_title(\"Satellite Image\")\n","    axarr[1].imshow(np.squeeze(Y_train[i]))\n","    axarr[1].set_title(\"Label/Ground Truth Image\")"]},{"cell_type":"markdown","metadata":{"id":"gxFXjrLRFOAn"},"source":["# **INITIALIZE MODEL TRAINING PARAMETERS**"]},{"cell_type":"markdown","metadata":{"id":"DqHcdAsPiXHT"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h4Z3Jyb6eqgs"},"outputs":[],"source":["# Here define the evaluation metrics - Precision, Recall, FScore, IoU\n","metrics = [sm.metrics.Precision(threshold=0.5),sm.metrics.Recall(threshold=0.5),sm.metrics.FScore(threshold=0.5,beta=1),sm.metrics.IOUScore(threshold=0.5)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lgzEIQ99we07"},"outputs":[],"source":["# Loss function\n","import tensorflow.keras.backend as K\n","\n","smooth = 1\n","\n","def dsc(y_true, y_pred):\n","    smooth = 1.\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","    return score\n","\n","def dice_loss(y_true, y_pred):\n","    loss = 1 - dsc(y_true, y_pred)\n","    return loss"]},{"cell_type":"markdown","metadata":{"id":"hc8kILkP7E8K"},"source":["# **U-Net Segmentation Model**\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YsntMSoge-br"},"outputs":[],"source":["# Model training - Results are saved in a .csv file\n","\n","# Size of the tiles/patches\n","size = X_train.shape[2] # This line takes the value of the 3rd index which in this is taken from X_train shape = 1000, 64, 64, 4, that is 64.\n","\n","# Image bands\n","img_bands = X_train.shape[3] # This line takes the value of the 4th index which in this is taken from X_train shape = 1000, 64, 64, 4, that is 4.\n","\n","# Loss function.\n","loss=dice_loss\n","\n","# Number of filters. We set a range of the number of filters for the convolutional layers.\n","filters = [4, 8,16,32,64]\n","\n","# The learning rate is a tuning parameter in an optimization algorithm that determines the step size\n","# at each iteration while moving toward a minimum of a loss function.\n","\n","lr = [10e-3, 5e-4, 10e-4, 5e-5, 10e-5]\n","\n","# Batch sizes. This considers how many patches the model will take during the training phases. A value of 4 means 4 patches of images (from 1000) will be taken as a batch while training simultaneously.\n","batch_size = [4, 8, 16, 32]\n","\n","# Epochs. The number of iterations the model will train.\n","epochs = 100 #try with different epochs from 5-100/200 based on the size of your training samples\n","\n","# Dictionary that will save the results.\n","dic = {}\n","\n","# Hyperparameters. These are the keys where the associated information for each hyperparameter will be saved.\n","dic[\"model\"] = [] # Name of the model\n","dic[\"batch_size\"] = [] # Batch Size\n","dic[\"learning_rate\"] = [] # Learning rate\n","dic[\"filters\"] = [] # Number of filters\n","\n","# Metrics on the test set. It will save the metrics after evaluating the model on the test set.\n","dic[\"precision_area\"] = []\n","dic[\"recall_area\"] = []\n","dic[\"f1_score_area\"] = []\n","dic[\"IOU_Score\"] = []\n","dic[\"accuracy\"] = []\n","dic[\"loss\"] = []\n","\n","## Here a nested for-loop performed to check all possible hyperparameter combinations that we set above.\n","\n","######################################## List to store results during the loop\n","results_list = []\n","\n","# loop over all the filters in the filter list\n","for fiilter in filters:\n","    # loop over the learning rates\n","    for learning_rate in lr:\n","        # loop over all batch sizes in batch_size list\n","        for batch in batch_size:\n","            print('_______________________________________________________________________________')\n","            print('Filters: ', fiilter)\n","            print('Learning rate: ', learning_rate)\n","            print('Batch size: ', batch)\n","\n","            # define the model architecture here.\n","            def unet(lr,filtersFirstLayer, pretrained_weights = None,input_size = (size,size,img_bands)):\n","                inputs = Input(input_size)\n","                conv1 = Conv2D(filtersFirstLayer, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(inputs)\n","                conv1 = Conv2D(filtersFirstLayer, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv1)\n","                pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","                conv2 = Conv2D(filtersFirstLayer*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool1)\n","                conv2 = Conv2D(filtersFirstLayer*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv2)\n","                pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","                conv3 = Conv2D(filtersFirstLayer*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool2)\n","                conv3 = Conv2D(filtersFirstLayer*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv3)\n","                pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","                conv4 = Conv2D(filtersFirstLayer*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool3)\n","                conv4 = Conv2D(filtersFirstLayer*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv4)\n","                pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","                conv5 = Conv2D(filtersFirstLayer*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(pool4)\n","                conv5 = Conv2D(filtersFirstLayer*16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv5)\n","\n","                up6 = Conv2D(filtersFirstLayer*8, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(UpSampling2D(size = (2,2))(conv5))\n","                merge6 = concatenate([conv4,up6], axis = 3)\n","                conv6 = Conv2D(filtersFirstLayer*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge6)\n","                conv6 = Conv2D(filtersFirstLayer*8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv6)\n","\n","                up7 = Conv2D(filtersFirstLayer*4, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(UpSampling2D(size = (2,2))(conv6))\n","                merge7 = concatenate([conv3,up7], axis = 3)\n","                conv7 = Conv2D(filtersFirstLayer*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge7)\n","                conv7 = Conv2D(filtersFirstLayer*4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv7)\n","\n","                up8 = Conv2D(filtersFirstLayer*2, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(UpSampling2D(size = (2,2))(conv7))\n","                merge8 = concatenate([conv2,up8], axis = 3)\n","                conv8 = Conv2D(filtersFirstLayer*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge8)\n","                conv8 = Conv2D(filtersFirstLayer*2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv8)\n","\n","                up9 = Conv2D(filtersFirstLayer, 2, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(UpSampling2D(size = (2,2))(conv8))\n","                merge9 = concatenate([conv1,up9], axis = 3)\n","                conv9 = Conv2D(filtersFirstLayer, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(merge9)\n","                conv9 = Conv2D(filtersFirstLayer, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv9)\n","                conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'glorot_normal')(conv9)\n","                conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n","\n","                model = Model(inputs, conv10)\n","\n","                model.compile(optimizer=Adam(learning_rate=lr), loss=loss, metrics=[metrics,'accuracy'])\n","\n","                #model.summary()\n","\n","                if(pretrained_weights):\n","                    model.load_weights(pretrained_weights)\n","\n","                return model\n","\n","            # Load the model in a new variable called \"model\".\n","            model = unet(filtersFirstLayer= fiilter, lr = learning_rate, input_size = (size,size,img_bands))\n","\n","            # Stop the training if the validation loss does not decrease after 30 epochs. This is done to avoid over-fitting of the model.\n","            early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss',\n","                              patience = 30, # how many epochs to continue running the model after not seeing any change in the \"val_loss\"/you can change it\n","                              restore_best_weights = True) # update the model weights\n","\n","            # Save the models only when validation loss decrease\n","            model_checkpoint = tf.keras.callbacks.ModelCheckpoint(f'/content/drive/MyDrive/Data for the experiment/Results/weights/unet_size_{size}_filters_{fiilter}_batch_size_{batch}_lr_{learning_rate}.hdf5',\n","                                                                  monitor='val_loss', mode='min',verbose=0, save_best_only=True,save_weights_only = True)\n","            #here, the weights will be saved in the following folder in the google drive: /content/drive/MyDrive/Data for the experiment/Results/weights.../you have to mention\n","\n","            # fit the model with 25% of the dataset used as the validation set\n","            history = model.fit(X_train,Y_train,\n","                                validation_data=(X_val, Y_val), #validation_split=0.2...if you use the validation data from the train set\n","                                batch_size = batch,epochs=epochs,\n","                                callbacks = [model_checkpoint, early_stop], verbose=1)\n","\n","            # Data augmentation: define geometric transformation of original training images//If you want to apply the data augmentation techniques,\n","            #uncomment the following lines of code and comment the previous lines of code to fit model \n","\n","            #data_aumentation_flag = 1\n","\n","            #train_generator = ImageDataGenerator(\n","                #featurewise_center=True,\n","                #featurewise_std_normalization=True,\n","                #width_shift_range=0.2,\n","                #height_shift_range=0.2,\n","                #rotation_range=20,\n","                #zoom_range=[1.0,1.2],\n","                #horizontal_flip=True)\n","\n","            #train_generator.fit(X_train)\n","\n","            #val_generator = ImageDataGenerator(\n","                #featurewise_center=True,\n","                #featurewise_std_normalization=True)\n","\n","            #val_generator.fit(X_val)\n","\n","            #history = model.fit(train_generator.flow(X_train, Y_train, batch_size=batch),\n","                        #steps_per_epoch = X_train.shape[0] / batch,\n","                        #epochs = epochs,\n","                        #validation_data=val_generator.flow(X_val, Y_val),\n","                        #callbacks = [model_checkpoint, early_stop],\n","                        #verbose=1 )\n","\n","            # summarize history for f1-score\n","            plt.plot(history.history['f1-score'])\n","            plt.plot(history.history['val_f1-score'])\n","            plt.title('model f1-score')\n","            plt.ylabel('f1-score')\n","            plt.xlabel('epoch')\n","            plt.legend(['train', 'validation'], loc='upper left')\n","            # save plots locally\n","            plt.savefig(f\"/content/drive/MyDrive/Data for the experiment/Results/plots/unet_size_{size}_filters_{fiilter}_batch_size_{batch}_lr_{learning_rate}_f1_score.png\")\n","            #here, the plots will be saved in the following folder in the google drive: /content/drive/MyDrive/Data for the experiment/Results/plots..\n","            plt.show()\n","            # summarize history for loss\n","            plt.plot(history.history['loss'])\n","            plt.plot(history.history['val_loss'])\n","            plt.title('model loss')\n","            plt.ylabel('loss')\n","            plt.xlabel('epoch')\n","            plt.legend(['train', 'validation'], loc='upper left')\n","            plt.savefig(f\"/content/drive/MyDrive/Data for the experiment/Results/plots/unet_size_{size}_filters_{fiilter}_batch_size_{batch}_lr_{learning_rate}_val_loss.png\")\n","            plt.show()\n","\n","            # load unet to evaluate the test data\n","            load_unet = unet(filtersFirstLayer= fiilter, lr = learning_rate,input_size=(size,size,img_bands))\n","            # load the last saved weight from the training\n","            load_unet.load_weights(f\"/content/drive/MyDrive/Data for the experiment/Results/weights/net_size_{size}_filters_{fiilter}_batch_size_{batch}_lr_{learning_rate}.hdf5\")\n","\n","           # Here, evaluate the model performance on the test set, a set of data that the model has never seen before and therefore remains an objective tool to test the performance of the model.\n","            res_1= load_unet.evaluate(X_test,Y_test)\n","\n","          ########If you want to save the performance metrics for the train and validation data in a csv file\n","            res_2= load_unet.evaluate(X_train,Y_train)\n","            res_3= load_unet.evaluate(X_val,Y_val)\n","\n","\n","            # save results of the test data on the dictionary and then output them all in a Excel CSV file.\n","            dic[\"model\"].append(\"Unet\")\n","            dic[\"batch_size\"].append(batch)\n","            dic[\"learning_rate\"].append(learning_rate)\n","            dic[\"filters\"].append(fiilter)\n","            dic[\"loss\"].append(res_1[0])\n","            dic[\"precision_area\"].append(res_1[1])\n","            dic[\"recall_area\"].append(res_1[2])\n","            dic[\"f1_score_area\"].append(res_1[3])\n","            dic[\"IOU_Score\"].append(res_1[4])\n","            dic[\"accuracy\"].append(res_1[5])\n","\n","\n","            # Convert results to a dataframe\n","            results = pd.DataFrame(dic)\n","            # Export as csv\n","            results.to_csv(f'/content/drive/MyDrive/Data for the experiment/Results/csv/results_Unet.csv', index = False)\n","            # here, the csv file will be saved in the following folder in the google drive: /content/drive/MyDrive/Data for the experiment/Results/csv..\n","            \n","            # Save results in the list for the train and validation datsets\n","            results_list.append({\n","               \"model\": \"Unet\",\n","               \"batch_size\": batch,\n","               \"learning_rate\": learning_rate,\n","               \"filters\": fiilter,\n","               \"training_loss_train\": res_2[0],\n","               \"training_precision_area_train\": res_2[1],\n","               \"training_recall_area_train\": res_2[2],\n","               \"training_f1_score_area_train\": res_2[3],\n","               \"training_IOU_Score_train\": res_2[4],\n","               \"training_accuracy_train\": res_2[5],\n","               \"validation_loss_val\": res_3[0],\n","               \"validation_precision_area_val\": res_3[1],\n","               \"validation_recall_area_val\": res_3[2],\n","               \"validation_f1_score_area_val\": res_3[3],\n","               \"validation_IOU_Score_val\": res_3[4],\n","               \"validation_accuracy_val\": res_3[5]\n","            })\n","           # Convert results_list to a DataFrame\n","            results_1 = pd.DataFrame(results_list)\n","\n","           # Export as csv for the train and validation data\n","            results_1.to_csv(f'/content/drive/MyDrive/Data for the experiment/Results/csv/results_1_Unet.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"psGdwpj-SZNE"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"cxZyePSLXzuR"},"source":["# **PREDICT LANDSLIDES ON THE TEST SET**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2EsaoELTe-60"},"outputs":[],"source":["# Load the best model based on the best performances on the test set (check CSV file)\n","# Loading the model weights\n","unet_best = unet(filtersFirstLayer= 8,lr = 0.001,input_size=(size,size,img_bands)) #  use the same number of filters and learning rate of the chosen model to initialise the network.\n","unet_best.load_weights(\"/content/drive/MyDrive/Data for the experiment/Results/weights/unet_size_64_filters_8_batch_size_8_lr_0.001.hdf5\")\n","\n","no = 100   #X_test.shape[0]\n","# Plot predictions on test set\n","for i in range(no):\n","    preds_train_1 = unet_best.predict(np.expand_dims(X_test[i],axis = 0), verbose=0)\n","    # It's possible to change the 0.5 threshold to improve the results;\n","    preds_train_t1 = (preds_train_1 > 0.5).astype(np.uint8)\n","    f, axarr = plt.subplots(1,3,figsize=(10,10))\n","    axarr[0].imshow(X_test[i][:,:,:3])\n","    axarr[0].set_title(\"Satellite image\")\n","    axarr[1].imshow(np.squeeze(preds_train_t1))\n","    axarr[1].set_title(\"Predictions made by the model\")\n","    axarr[2].imshow(np.squeeze(Y_test[i]))\n","    axarr[2].set_title(\"Label/Ground truth image\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
